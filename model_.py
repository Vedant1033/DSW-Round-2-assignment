# -*- coding: utf-8 -*-
"""model_

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UngG-UsY9k52G-bBPX3B9GhchNnwqsZm
"""



"""# **Preprocessing **
Import necessary libraries and modules
Load the training dataset from the provided file path
Initialize the preprocessing pipeline for handling categorical and numerical data
Preprocess the data:
  - Encode categorical variables
  - Standardize numerical features

Split the data into training and validation sets for model evaluation
"""

import pandas as pd

# Load the train and test data
train_file_path = 'train_data.xlsx'
test_file_path = 'test_data.xlsx'

train_data = pd.read_excel(train_file_path)
test_data = pd.read_excel(test_file_path)

# Display basic information about both datasets
train_info = train_data.info()
test_info = test_data.info()

train_head = train_data.head()
test_head = test_data.head()

train_info, test_info, train_head, test_head

"""# Creating a class for model pipeline      """

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier

class ModelPipeline:
    def __init__(self, model):
        self.model = model
        self.label_encoders = {}
        self.scaler = None

    def load(self, file_path):
        return pd.read_excel(file_path)

    def preprocess(self, data, is_training=True):
        # Label Encoding for categorical variables
        categorical_features = ['sub_grade', 'term', 'home_ownership', 'purpose',
                                 'application_type', 'verification_status']
        if is_training:
            for col in categorical_features:
                le = LabelEncoder()
                data[col] = le.fit_transform(data[col])
                self.label_encoders[col] = le
        else:
            for col in categorical_features:
                data[col] = self.label_encoders[col].transform(data[col])

        # Scale numerical variables
        numerical_features = ['cibil_score', 'total_no_of_acc', 'annual_inc',
                              'int_rate', 'loan_amnt', 'installment', 'account_bal', 'emp_length']
        if is_training:
            self.scaler = StandardScaler()
            data[numerical_features] = self.scaler.fit_transform(data[numerical_features])
        else:
            data[numerical_features] = self.scaler.transform(data[numerical_features])

        return data

    def train(self, X_train, y_train):
        self.model.fit(X_train, y_train)

    def test(self, X_val, y_val):
        predictions = self.model.predict(X_val)
        report = classification_report(y_val, predictions)
        accuracy = accuracy_score(y_val, predictions)
        return report, accuracy

    def predict(self, X):
        return self.model.predict(X)

# Example Usage
if __name__ == "__main__":
    # Load the data
    train_file = 'train_data.xlsx'
    test_file = 'test_data.xlsx'

    train_data = pd.read_excel(train_file)
    test_data = pd.read_excel(test_file)

    # Initialize pipelines for each model
    lr_pipeline = ModelPipeline(LogisticRegression(max_iter=1000, random_state=42))
    rf_pipeline = ModelPipeline(RandomForestClassifier(random_state=42))
    knn_pipeline = ModelPipeline(KNeighborsClassifier())
    xgb_pipeline = ModelPipeline(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))


    # Preprocess data
    train_data = lr_pipeline.preprocess(train_data, is_training=True)
    X = train_data.drop(columns=['loan_status', 'customer_id', 'transaction_date'])
    y = train_data['loan_status']
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **Model Evaluation**"""

# Logistic Regression
lr_pipeline.train(X_train, y_train)
report, accuracy = lr_pipeline.test(X_val, y_val)
print("Logistic Regression Results:\\n", report, "\\nAccuracy:", accuracy)

# Random Forest
rf_pipeline.train(X_train, y_train)
report, accuracy = rf_pipeline.test(X_val, y_val)
print("Random Forest Results:\\n", report, "\\nAccuracy:", accuracy)

# K-Nearest Neighbors
knn_pipeline.train(X_train, y_train)
report, accuracy = knn_pipeline.test(X_val, y_val)
print("KNN Results:\\n", report, "\\nAccuracy:", accuracy)

# XGBoost Classifier
xgb_pipeline.train(X_train, y_train)
report, accuracy = xgb_pipeline.test(X_val, y_val)
print("XGBoost Classifier Results:\\n", report, "\\nAccuracy:", accuracy)